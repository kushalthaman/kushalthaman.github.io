---
---


@article{forthcoming, 
author = {Dron Hazra and Alex Bie and Mantas Mazeika and Xuwang Yin and Kushal Thaman and Andy Zou and Maximilian Kaufmann and Dan Hendrycks},
year = {2024.},
title = {RenderAttack: Hundreds of Adversarial Attacks Through Differentiable Texture Generation}, 
preview = {renderattack.png},
journal = {Under review},
abstract = {A longstanding problem in adversarial robustness has been defending against attacks beyond standard $\ell_p$ threat models. However, the space of possible non-$\ell_p$ attacks is vast, and existing work has only developed a small number of attacks due to the manual effort required. Building on recent progress in differentiable material rendering, we propose RenderAttack, a framework for developing large numbers of structurally diverse, non-$\ell_p$ adversarial attacks. Using this framework, we curate 167 new attacks with professionally-designed assets and introduce the ImageNet-RA benchmark. In experiments, we find that ImageNet-RA exposes new regions of attack-space, in some cases significantly altering the ranking of defenses. By comparing state-of-the-art models and defenses, we identify promising directions for future work in ensuring robustness to a wide range of test-time adversaries.},
}

@article{2312.03096,
Author = {Victor Lecomte* and Kushal Thaman* and Rylan Schaeffer and Naomi Bashkansky and Trevor Chow and Sanmi Koyejo.},
Title = {What Causes Polysemanticity? An Alternative Origin Story of Mixed Selectivity from Incidental Causes},
Year = {2024.},
journal = {Accepted as a poster at the Representational Alignment and BGPT workshops at the International Conference on Learning Representations (ICLR)},
preview = {sparsity.png},
pdf = {https://arxiv.org/pdf/2312.03096.pdf},
bibtex_show = {true},
abstract = {Polysemantic neurons (neurons that activate for a set of unrelated features) have been seen as a significant obstacle towards interpretability of task-optimized deep networks, with implications for AI safety. The classic origin story of polysemanticity is that the data contains more "features" than neurons, such that learning to perform a task forces the network to co-allocate multiple unrelated features to the same neuron, endangering our ability to understand the network's internal processing. In this work, we present a second and non-mutually exclusive origin story of polysemanticity. We show that polysemanticity can arise incidentally, even when there are ample neurons to represent all features in the data, using a combination of theory and experiments. This second type of polysemanticity occurs because random initialization can, by chance alone, initially assign multiple features to the same neuron, and the training dynamics then strengthen such overlap. Due to its origin, we term this incidental polysemanticity.},
eprint= {arXiv:2312.03096}
}

@ARTICLE{2021LPI....52.2764J,
  author = {Thaman, Kushal and Jayam, Viraj and Kim, Jeffrey and Jain, Shaurya and Xue, QiLin and Datta., Ashmit},
  year = {2021.},
  title = {An Analytic Model of Stable and Unstable Orbital Resonance},
  journal = {In 52nd Lunar and Planetary Science Conference},
  preview = {orbital.png}, 
  abstract = {The purpose of this paper is to develop a model for orbital resonance, both when it leads to unstable chaotic orbits and when it leads to stable configurations. The study of resonance is a great interest in astronomy as it can give clues to the formation of the early solar system by analyzing where certain objects are, and where there is a characteristic lack of objects. This paper applies elementary techniques from Newtonian mechanics to accurately and reliably predict the relative strengths of Kirkwood gaps in the main asteroid belt. It also builds off of prior work to create a more updated and complete approximation of the liberation period in stable resonant systems such as Saturnâ€™s moons Titan and Hyperion},
  url = {https://ui.adsabs.harvard.edu/abs/2021LPI....52.2764J/},
}
