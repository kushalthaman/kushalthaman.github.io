---
---

@article{2312.03096,
Author = {Victor Lecomte* and Kushal Thaman* and Rylan Schaeffer and Naomi Bashkansky and Trevor Chow and Sanmi Koyejo.},
Title = {Incidental Polysemanticity},
Year = {2024.},
journal = {under review at the International Conference on Machine Learning},
preview = {sparsity.png},
pdf = {https://drive.google.com/file/d/1MpdAQht5Z2_K6EuGIOsrW-xzvSBBPcJC/view?usp=sharing},
bibtex_show = {true},
abstract = {Polysemantic neurons (neurons that activate for a set of unrelated features) have been seen as a significant obstacle towards interpretability of task-optimized deep networks, with implications for AI safety. The classic origin story of polysemanticity is that the data contains more "features" than neurons, such that learning to perform a task forces the network to co-allocate multiple unrelated features to the same neuron, endangering our ability to understand the network's internal processing. In this work, we present a second and non-mutually exclusive origin story of polysemanticity. We show that polysemanticity can arise incidentally, even when there are ample neurons to represent all features in the data, using a combination of theory and experiments. This second type of polysemanticity occurs because random initialization can, by chance alone, initially assign multiple features to the same neuron, and the training dynamics then strengthen such overlap. Due to its origin, we term this incidental polysemanticity.},
eprint= {arXiv:2312.03096}
}

@ARTICLE{2021LPI....52.2764J,
  author = {Jayam*, Viraj and Thaman*, Kushal and Kim, Jeffrey and Jain, Shaurya and Xue, QiLin and Datta., Ashmit},
  year = {2021.},
  title = {An Analytic Model of Stable and Unstable Orbital Resonance},
  journal = {In 52nd Lunar and Planetary Science Conference},
  preview = {orbital.png},
  url = {https://ui.adsabs.harvard.edu/abs/2021LPI....52.2764J/},
}
